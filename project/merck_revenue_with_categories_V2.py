# -*- coding: utf-8 -*-
"""Copy of Merck Revenue with Categories.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yel5qGLKBd4FK9Yw1IP8UL4xmeBJP232
"""


#V2 on 4/2/2024

import os


import pandas as pd
import numpy as np
import pyodbc
import datetime
import openpyxl
from dateutil.relativedelta import relativedelta
import os 


SERVER = os.getenv('SERVER')
DB = os.getenv('DB')
USERNAME = os.getenv('USERNAME')
PASSWORD = os.getenv('PASSWORD')
SERVER='sichemex.fortiddns.com,1444'
DB='dbwins_cmx'
USERNAME='chemex'
PASSWORD=r'6vQ~cDx6yCpP(CQ`'

cnxn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+SERVER+';DATABASE='+DB+';UID='+USERNAME+';PWD='+ PASSWORD)
cursor = cnxn.cursor()

# Commented out IPython magic to ensure Python compatibility.
# %%sh
# lsb_release -a

def retreive_val ( query):
    """execute query and turn the data in the a list of dict

    Args:
        query (_type_): _description_

    Returns:
        list of dictionary: all data from the data as a list of dict
    """
    cursor.execute(query)
    result = cursor.fetchall()
    col = [column[0] for column in cursor.description]
    result_LoD = [dict(zip(col,x)) for x in result ]
    # LoD = list of dict
    return col,result_LoD

if __name__ == '__main__':
  # Get revenue data from the database
  revenue_pd = pd.DataFrame(retreive_val("""select * from bi_revenue where docuno like 'IVZ%'
                                        and  (year(docudate)=2023 or year(docudate)=2024 ) 
                                        and แบรนด์ in 
                                        ('Sigma-Aldrich', 'Supelco', 'Roche', 'Sigma', 'Millipore', 'Aldrich', 'Supelco', 'Merck')
                                        """)[1])

  # If file not found, copy the file path from the panel on the left (assuming you are on GDrive)
  cat_pd = pd.read_csv('project/cleaned_unique_category.csv',encoding = 'unicode_escape')



  revenue_pd_dict = revenue_pd.to_dict('records')
  cat_pd_dict = cat_pd.to_dict('records')


  

  for r in revenue_pd_dict:
    # Initialize to be NOT FOUND first
    r['found'] = False
    r['รหัสสินค้า'] = r['รหัสสินค้า'].upper()
    # Loop through the category dictionary
    for c in cat_pd_dict:
      if isinstance(c['product_code'], str):
        if r['รหัสสินค้า'].upper() == c['product_code'].upper():
          for k,v in c.items():
            if k != 'product_code' and k != 'product_description':
              r[k] = c[k]
              r['found']= True
        else:
          if 'SIA' in r['รหัสสินค้า'].upper() and r['รหัสสินค้า'].count('-')==2:
            if r['รหัสสินค้า'].split('-')[1] in  c['product_code'].upper():
              for k,v in c.items():
                if k != 'product_code' and k != 'product_description':
                  r[k] = c[k]
                  r['found']= True
      else:
        cap_list = [x.upper() for x in c['product_code']]

        if r['รหัสสินค้า'].upper() in cap_list:
          for k,v in c.items():
            if k != 'product_code' and k != 'product_description':
              r[k] = c[k]
              r['found']= True
        else:
          if 'SIA' in r['รหัสสินค้า'].upper() and r['รหัสสินค้า'].count('-')==2:
            if r['รหัสสินค้า'].split('-')[1] in  cap_list:
              for k,v in c.items():
                if k != 'product_code' and k != 'product_description':
                  r[k] = c[k]
                  r['found']= True
  
# V2 starts here

  product_sold_past = revenue_pd.copy() 
  # All products sold (from our DB)
  product_sold_past.columns
  product_col = ['แบรนด์','รหัสสินค้า', 'รายละเอียดสินค้า']
  product_sold_past = product_sold_past.drop(columns = [a for a in product_sold_past.columns if a not in product_col])
  product_sold_past.drop_duplicates(subset=['รหัสสินค้า','แบรนด์'], keep='first', inplace=True)

    # File location 
  # /home/twrx/W/DataENV/Merck Product Categorization 2024
  bioM = "project/BioM Product list.csv"
  biology = "project/Millipore product - LR4_Biology 2023.csv"
  chemistry = "project/Processed Stockcode for Chemistry_Merck.csv"

  # Read csv's
  bioM_pd = pd.read_csv(bioM)
  biology_pd = pd.read_csv(biology)
  chemistry_pd = pd.read_csv(chemistry)

  keep_col = ['Stockcode', 'Descripiton', 'Cat', 'Sub Cat', 'SBU']

  # print(list(a for a in bioM_pd.columns if a not in keep_col))
  bioM_pd = bioM_pd.drop(columns= list(a for a in bioM_pd.columns if a not in keep_col))
  bioM_pd = bioM_pd.fillna("")
  bioM_pd['Stockcode']= bioM_pd['Stockcode'].apply(lambda x:f"{x[:6]}.{x[6:]}")
  # bioM_pd.head(10)
  bioM_merged = bioM_pd.merge(product_sold_past, left_on = "Stockcode", right_on = "รหัสสินค้า", how='right')
  empty = bioM_merged['Descripiton'].isnull()
  not_found_bioM =  bioM_merged[empty]
  bioM_matched = bioM_merged[~empty]
  assert not_found_bioM.shape[0]+bioM_matched.shape[0] == product_sold_past.shape[0]

  # Need this because NEW biology file does not contain granular detail
  prev_clean = pd.read_csv("project/cleaned_unique_category.csv", encoding = 'unicode_escape')
  prev_clean.head(10)
  # biology_pd['Stockcode'] = biology_pd['Stockcode'].str.lower() 
  # prev_clean['product_code'] = prev_clean['product_code'].str.lower()
  new_biology_pd = prev_clean.merge(biology_pd, left_on = 'product_code', right_on ="Stockcode", how='right')
  new_biology_pd.drop(columns=['product_code', 'product_description'], inplace=True)
  # new_biology_pd = new_biology_pd.fillna("")
  biology_merged = product_sold_past.merge(new_biology_pd , left_on = "รหัสสินค้า", right_on = "Stockcode", how='left')
  biology_merged.drop_duplicates(subset=['รหัสสินค้า'], keep='first', inplace=True)

  empty = biology_merged['Descripiton'].isnull()
  not_found_biology =  biology_merged[empty]
  biology_matched = biology_merged[~empty]
  assert biology_matched.shape[0]+not_found_biology.shape[0] == product_sold_past.shape[0]

  chemistry_merged = chemistry_pd.merge(product_sold_past, left_on = "Stockcode", right_on = "รหัสสินค้า", how='right')
  empty = chemistry_merged['Descripiton'].isnull()
  not_found_chemistry =  chemistry_merged[empty]
  chemistry_matched = chemistry_merged[~empty]
  assert chemistry_matched.shape[0]+not_found_chemistry.shape[0] == product_sold_past.shape[0]


  # Not found 
  temp = pd.concat([not_found_chemistry,not_found_biology, not_found_bioM ], ignore_index= True)
  # temp = pd.concat(temp, not_found_bioM,ignore_index= True)

  # Sicnce we combine all so there will be duplicates
  dedup = temp.drop_duplicates(subset=['รหัสสินค้า'], keep='first')
  dedup = dedup.reset_index(drop=True)


  #Now we need to try to match the previous versoin again (above, we only do it for biology)
  prev_clean = pd.read_csv("project/cleaned_unique_category.csv", encoding = 'unicode_escape')

  dedup_merge = dedup.merge(prev_clean, indicator=True, left_on = 'รหัสสินค้า', right_on = 'product_code', suffixes=('_x', ''),how='outer')
  dedup_merge.drop(dedup_merge.filter(regex='_x$').columns, axis=1 , inplace=True)
  unmatched = dedup_merge.query("_merge != 'both' ")
  matched = dedup_merge.query("_merge == 'both' ")

  # Concat all matched records
  final_merge = pd.concat([bioM_matched,biology_matched,chemistry_matched,matched])
  final_merge.drop_duplicates(subset=['รหัสสินค้า'], inplace=True)
  final_merge.reset_index(drop=True, inplace=True)

  # Fill in and keep only wanted columns
  mapping = {'รหัสสินค้า': ['Stockcode', 'product_code'],
            'รายละเอียดสินค้า': ['Descripiton', 'product_description'],
            'Cat': ['business_unit_desc'],
              'Sub Cat': ['business_field_desc'],
              'SBU': ['sbu_description']}
  for k,v in mapping.items():
      # print(k,v)
      for val in v:
          final_merge[k] =final_merge.apply(lambda x:x[k] if pd.notna(x[k]) else str(x[val]), axis=1)     

  

      
  # Unmatched
  temp['_merge'] = None

  # temp = not matched data from Merck's file, unmatched = also not matched from the old categories file (cleaned_unique_category.csv)
  final_unmatched = pd.concat([temp, unmatched], ignore_index= True)
  # Drop all rows that's from unmatched rows from Categories File (Since we only care about what we sold)
  final_unmatched =final_unmatched[final_unmatched['_merge']!= 'right_only']
  final_unmatched['รหัสสินค้า']=final_unmatched.apply(lambda x:x['รหัสสินค้า'] if x['รหัสสินค้า'] else x['product_code'], axis=1)
  final_unmatched.drop_duplicates(subset=['รหัสสินค้า'], inplace=True)
  # Because unfound from new Merck's category file may be found now (from temp variable), we want to exclude that if now they are found
  overlapped= final_unmatched['รหัสสินค้า'].isin(final_merge['รหัสสินค้า'])
  final_unmatched = final_unmatched[~overlapped]
  final_unmatched.reset_index(drop=True, inplace=True)

  # Now since the old categories file Product Code actually may contain list of codes 
  # We will try to match them again 
  unmatched_dict = final_unmatched.to_dict('records')
  prev_clean_dict = prev_clean.to_dict('records')

  found_idx = []

  # 
  for idx, m in enumerate(unmatched_dict):
      for p in prev_clean_dict: 
          m_name = m['รหัสสินค้า'].lower().strip()
          # product code is a list
          for l in p:
              p_name = p['product_code'].lower().strip()
              if m_name == p_name and idx not in found_idx:
                  m['Cat'] = p['business_unit_desc']
                  m['Sub Cat'] = p['business_field_desc']
                  m['SBU'] = p['sbu_description']
                  found_idx.append(idx)
              elif 'sia' in m_name and idx not in found_idx:
                  m_name = m_name.replace('sia',  "")
                  if m_name[:len(m_name)-3] in p_name:
                      m['Cat'] = p['business_unit_desc']
                      m['Sub Cat'] = p['business_field_desc']
                      m['SBU'] = p['sbu_description']
                      found_idx.append(idx)
                  
              elif m_name[:5] == p_name[:5]  and idx not in found_idx:
                  m['Cat'] = p['business_unit_desc']
                  m['Sub Cat'] = p['business_field_desc']
                  m['SBU'] = p['sbu_description']
                  found_idx.append(idx)
              

  all_unmatched = list(range(0, len(unmatched_dict)))
  not_found_index = list(set(all_unmatched) - set(found_idx))
  new_found = list(unmatched_dict[i] for i in found_idx )
  new_notfound = list(unmatched_dict[i] for i  in not_found_index )

  original_merge = final_merge.to_dict('records')
  original_merge.extend(new_found)

  # original_merge
  final_merge = pd.DataFrame(original_merge)
  final_unmatched = pd.DataFrame(new_notfound)
  final_merge.drop(columns= [x for x in final_merge.columns if x not in mapping.keys()], inplace=True)   
  rename_dict = {
    "Cat": "business_unit_desc",
    "Sub Cat" : 'business_field_desc',
    "SBU" : 'sbu_description',
  }
  final_merge.rename(columns= rename_dict, inplace=True)
  # final_merge_dict = final_merge.to_dict('records')
  
  
  ######End V2 #####
  
  

  """# New Section"""

  searched = pd.DataFrame(revenue_pd_dict)
  not_found = searched[~searched['found']]
  second_merge = not_found.merge(final_merge, left_on= 'รหัสสินค้า', right_on='รหัสสินค้า', how='inner')
  print(searched)
  merck_brand = ['Sigma-Aldrich', 'Supelco', 'Roche', 'Sigma', 'Millipore', 'Aldrich', 'Supelco', 'Merck']
  searched= searched[searched['แบรนด์'].isin(merck_brand)]
  print(searched.columns)
  drop_col = ['product_code', 'product_description']
  for d in drop_col:
    if d in searched.columns:
      searched.drop(columns=[d])

  searched = pd.concat([searched, second_merge], ignore_index=True)
  searched.drop_duplicates(subset=['docuno','รหัสสินค้า'], keep='first', inplace=True)
  searched.dropna(subset=['business_unit_desc'], inplace=True)
  searched.to_csv('searched.csv')

  searched['found'].value_counts()

  # Unmatched product based on the data provided from Merck.
  # I suspect that the unmatched products are other product categories since we only have the categories from Merck SLS (life science)
  # For example, top 3 products listed here are under industrial microbiology which is another BU in MERCK
  # unfound_pd= searched[~searched['found']][['รหัสสินค้า','รายละเอียดสินค้า']].value_counts().rename_axis(['product_code','description']).reset_index(name='counts')
